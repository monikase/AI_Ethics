# Fairness Definition Selection Tool

## 1. Introduction

**The Fairness Definition Selection Tool** (FDST) is a structured methodology that helps engineering teams **select, justify, and document appropriate fairness definitions** for AI systems.

Its core purpose is to prevent two common failure modes in fairness work:

**1. Metric shopping** – choosing a fairness metric because it is easy to implement rather than ethically or legally appropriate.  
**2. False completeness** – attempting to satisfy multiple incompatible fairness definitions simultaneously, despite known impossibility results.  

This tool ensures fairness evaluations:

- Align with historical discrimination patterns
- Respect legal and regulatory requirements
- Reflect stakeholder values and harm asymmetries
- Explicitly acknowledge trade-offs and limitations.

It is intended to be used before mitigation or optimization, shaping what “fairness” means for this system, in this context.
